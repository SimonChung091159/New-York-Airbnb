{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns \n",
    "import matplotlib.pyplot as plt \n",
    "import numpy as np \n",
    "import math\n",
    "import geopandas as gpd\n",
    "import csv\n",
    "\n",
    "#import geoplot as gplt\n",
    "\n",
    "\n",
    "from datetime import datetime\n",
    "from pylab import *\n",
    "from shapely.ops import nearest_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('nyc_airbnb.csv')\n",
    "df2 = pd.read_csv('NYC_Citywide_Annualized_Calendar_Sales_Update.csv')\n",
    "geo_ny = gpd.read_file('./Individual_Landmark_Lots/Individual_Landmark_Lots.shp')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                                    0\n",
       "neighbourhood_group                   0\n",
       "neighbourhood                         0\n",
       "latitude                              0\n",
       "longitude                             0\n",
       "room_type                             0\n",
       "price                                 0\n",
       "minimum_nights                        0\n",
       "number_of_reviews                     0\n",
       "last_review                       10051\n",
       "reviews_per_month                 10051\n",
       "calculated_host_listings_count        0\n",
       "availability_365                      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#CLEAN AIRBNB DATASET (df)\n",
    "\n",
    "#drop unused column\n",
    "df.drop(['host_name','host_id','name'], axis=1, inplace=True)\n",
    "\n",
    "#Only keep data with positive price\n",
    "df = df[df[\"price\"] > 0]\n",
    "\n",
    "#drop duplicate\n",
    "df = df.drop_duplicates()\n",
    "\n",
    "#check null data\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chila\\miniconda3\\envs\\cs_ftmle\\lib\\site-packages\\ipykernel_launcher.py:22: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\Users\\chila\\miniconda3\\envs\\cs_ftmle\\lib\\site-packages\\pandas\\core\\frame.py:4164: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  errors=errors,\n"
     ]
    }
   ],
   "source": [
    "#EDIT/ADD COLUMNS TO AIRBNB DATASET (df)\n",
    "\n",
    "#add activity column\n",
    "#activity = No Record if no last review\n",
    "#activity = Inactive if last review is not within 1year of the latest last_review\n",
    "#activity = Active otherwise\n",
    "\n",
    "#convert to datetime\n",
    "\n",
    "df['last_review'] = pd.to_datetime(df['last_review'])\n",
    "\n",
    "time_threshold = pd.to_datetime('2018/12/06')\n",
    "\n",
    "df.loc[df['last_review'] >= time_threshold, 'activity'] = 'Active'\n",
    "df.loc[df['last_review'] < time_threshold, 'activity'] = 'Inactive'\n",
    "df.loc[df['last_review'].isnull(), 'activity'] = 'No Record'\n",
    "\n",
    "df_active = df.loc[df['activity'] == 'Active']\n",
    "df_active\n",
    "\n",
    "#add occupancy_% column\n",
    "df_active['occupancy_%'] = round(100 - df_active['availability_365']/ 365 * 100).astype('float')\n",
    "\n",
    "#reset index\n",
    "df_active.reset_index(inplace=True)\n",
    "df_active.drop(['index'], axis=1, inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DETERMINE ON AVERAGE HOW FAR AN AIRBNB FROM ALL THE LANDMARKS OF NYC\n",
    "\n",
    "def haversine_distance(lat1, lon1, lat2, lon2):\n",
    "    '''\n",
    "    function to calculated distance in km based on long and lat\n",
    "    '''\n",
    "    r = 6371\n",
    "    phi1 = np.radians(lat1)\n",
    "    phi2 = np.radians(lat2)\n",
    "    delta_phi = np.radians(lat2 - lat1)\n",
    "    delta_lambda = np.radians(lon2 - lon1)\n",
    "    a = np.sin(delta_phi / 2)**2 + np.cos(phi1) * np.cos(phi2) *   np.sin(delta_lambda / 2)**2\n",
    "    res = r * (2 * np.arctan2(np.sqrt(a), np.sqrt(1 - a)))\n",
    "    return np.round(res, 2)\n",
    "\n",
    "def find_distance(df, df2):\n",
    "    how_far_list = []\n",
    "    for idx, item in df['coords'].iteritems():\n",
    "        distance_list = []\n",
    "        \n",
    "        for idx2, item2 in df2['coords'].iteritems():\n",
    "            #print(item, item2)\n",
    "            l = haversine_distance(item[1], item[0], item2[1], item2[0])\n",
    "            distance_list.append(l)\n",
    "            \n",
    "        mean_dist = mean(distance_list)   \n",
    "        how_far_list.append(mean_dist)\n",
    "        if idx % 1000 == 0:\n",
    "            print(idx)\n",
    "    return how_far_list\n",
    "\n",
    "   \n",
    "# geo_ny = geo_ny[['OBJECTID', 'geometry']]\n",
    "\n",
    "# geo_ny = geo_ny.to_crs(\"EPSG:4326\")  #convert to correct projection\n",
    "# geo_ny['coords'] = geo_ny['geometry'].apply(lambda x: x.representative_point().coords[:]) \n",
    "# geo_ny['coords'] = [coords[0] for coords in geo_ny['coords']]\n",
    "\n",
    "# df_geo = df_active[['latitude','longitude']]\n",
    "# df_geo = gpd.GeoDataFrame(df_geo, geometry=gpd.points_from_xy(df_geo.longitude, df_geo.latitude))\n",
    "\n",
    "# df_geo['coords'] = df_geo['geometry'].apply(lambda x: x.representative_point().coords[:]) \n",
    "# df_geo['coords'] = [coords[0] for coords in df_geo['coords']]\n",
    "\n",
    "\n",
    "# how_far_km = find_distance(df_geo, geo_ny)\n",
    "\n",
    "#save to csv so can import csv later to save time\n",
    "#how_far_df = pd.DataFrame(how_far_km, columns=[\"how_far_km\"])\n",
    "#how_far_df.to_csv('df_active_how_far_km2.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read how_far_km_csv_file and add to df_active\n",
    "df3 = pd.read_csv('df_active_how_far_km.csv')\n",
    "df3\n",
    "\n",
    "df_active = pd.concat([df_active, df3], axis = 1)\n",
    "df_active.to_csv('clean_nyc_airbnb.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CLEAN SALE_PRICE DATASET (df2)\n",
    "\n",
    "#drop unused column\n",
    "df2 = df2[['BOROUGH','NEIGHBORHOOD','SALE PRICE','SALE DATE','Latitude','Longitude']]\n",
    "\n",
    "#drop duplicate\n",
    "df2 = df2.drop_duplicates()\n",
    "\n",
    "#drop null data\n",
    "df2 = df2.dropna()\n",
    "\n",
    "#Rename borough\n",
    "\n",
    "df2.columns = ['neighbourhood_group','neighbourhood','sale_price','sale_date','latitude','longitude']\n",
    "\n",
    "df2['neighbourhood_group'] = df2['neighbourhood_group'].astype('str')\n",
    "\n",
    "df2['neighbourhood_group'].replace('1','Manhattan', inplace = True)\n",
    "df2['neighbourhood_group'].replace('2','Brooklyn', inplace = True)\n",
    "df2['neighbourhood_group'].replace('3','Queens', inplace = True)\n",
    "df2['neighbourhood_group'].replace('4','Bronx', inplace = True)\n",
    "df2['neighbourhood_group'].replace('5','Staten Island', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chila\\miniconda3\\envs\\cs_ftmle\\lib\\site-packages\\pandas\\core\\frame.py:4164: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  errors=errors,\n"
     ]
    }
   ],
   "source": [
    "#EDIT/ADD COLUMNS TO SALE_PRICE DATASET (df2)\n",
    "\n",
    "#convert to datetime\n",
    "df2['sale_date'] = pd.to_datetime(df2['sale_date'])\n",
    "\n",
    "lower_time_threshold = pd.to_datetime('2018/12/06')\n",
    "upper_time_threshold = pd.to_datetime('2019/12/06')\n",
    "\n",
    "df2 = df2.loc[df2['sale_date'] >= lower_time_threshold ]\n",
    "df_sale = df2.loc[df2['sale_date'] <= upper_time_threshold]\n",
    "\n",
    "#reset index\n",
    "df_sale.reset_index(inplace=True)\n",
    "df_sale.drop(['index'], axis=1, inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#DETERMINE ON AVERAGE HOW FAR A SALE PROPERTY FROM ALL THE LANDMARKS OF NYC\n",
    "\n",
    "# geo_ny = geo_ny[['OBJECTID', 'geometry']]\n",
    "# geo_ny = geo_ny.to_crs(\"EPSG:4326\")  #convert to correct projection\n",
    "# geo_ny['coords'] = geo_ny['geometry'].apply(lambda x: x.representative_point().coords[:]) \n",
    "# geo_ny['coords'] = [coords[0] for coords in geo_ny['coords']]\n",
    "\n",
    "# df_geo = df_sale[['latitude','longitude']]\n",
    "\n",
    "# df_geo = gpd.GeoDataFrame(df_geo, geometry=gpd.points_from_xy(df_geo.longitude, df_geo.latitude))\n",
    "# df_geo['coords'] = df_geo['geometry'].apply(lambda x: x.representative_point().coords[:]) \n",
    "# df_geo['coords'] = [coords[0] for coords in df_geo['coords']]\n",
    "\n",
    "# how_far_km = find_distance(df_geo, geo_ny)\n",
    "\n",
    "# print(df_geo['coords'].count)\n",
    "# print(len(how_far_km))\n",
    "\n",
    "# #save to csv so can import csv later to save time\n",
    "# how_far_df = pd.DataFrame(how_far_km, columns=[\"how_far_km\"])\n",
    "# how_far_df.to_csv('df_sale_how_far_km2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read csv_file and add to df_active\n",
    "df4 = pd.read_csv('df_sale_how_far_km.csv')\n",
    "df4\n",
    "\n",
    "df_sale = pd.concat([df_sale, df4], axis = 1)\n",
    "df_sale.to_csv('clean_nyc_sale.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
